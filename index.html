<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Weidi Xie</title>
  
  <meta name="author" content="Weidi Xie">
  <meta name="viewport" content="width=device-width", initial-scale="1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/svg+xml" href="images/icon.svg">
</head>

<body>
  <table id="container">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <p align="center">
              <a href=index.html>Home</a>&nbsp/&nbsp 
              <a href=about.html>About&nbspMe</a>&nbsp/&nbsp
              <a href=people.html>People</a>&nbsp/&nbsp
              <a href=research.html>Research</a>
            </p>
            <hr>
          </tr>
        </table>
      </td>
    </tr>
    <tr>
      <td>
        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="33%" valign="center">
              <img src="images/weidi_photo.png" width="220" height="220">
            </td>
            <td width="80%" valign="middle">
              <p align="center">
                <name>Weidi Xie<span style="font-family:STFangsong; font-size:20pt"> (谢伟迪)</span></name>
              </p>
              <br>
              <p align="center">
                 I'm a research fellow at <a href="http://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a>,
                 working on computer vision, deep learning, biomedical image analysis. <br> <br>

                 I'm always facinated by simple ideas that make vision work, if you share the same interest, 
                 and would like to explore potential collaborations, please get in touch.
              </p>
              <p> </p>
             
            </td>
          </tr>
        </table>
        <table width="120%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Contact Me</heading>
              <p>
                Department of Engineering Science, Oxford, UK - OX1 3PJ &nbsp/&nbsp
                <a href="mailto:weidi@robots.ox.ac.uk"> Email </a>&nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=Vtrqj4gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/WeidiXie"> Twitter </a> &nbsp/&nbsp
                <a href="https://space.bilibili.com/626918756"> Bilibili </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/weidi-xie-81a59976/"> LinkedIn </a>
              </p>
              <br>
              <heading>News</heading>
              <ul>
                <li><b> Dec 2021, </b> <a href="https://ju-chen.github.io/efficient-prompt/"> Prompting Visual-Language Models for Efficient Video Understanding.</a> Preprint.
                <li><b> Dec 2021, </b> <a href="https://charigyang.github.io/abouttime/"> It's About Time: Analog Clock Reading in the Wild.</a> Preprint.
                <li><b> Oct 2021, </b> <a href="https://www.robots.ox.ac.uk/~vgg/research/simo/"> Segmenting Invisible Moving Objects.</a> Accepted by BMVC2021.
                <li><b> Oct 2021, </b> <a href="https://www.robots.ox.ac.uk/~vgg/research/avs/"> Audio-Visual Synchronisation In The Wild.</a> Accepted by BMVC2021.
                <li><b> Oct 2021, </b> <a href="https://www.robots.ox.ac.uk/~vgg/research/pixelpick/"> All You Need Are a Few Pixels: Semantic Segmentation with PixelPick.</a>
                Accepted by ICCV21, ILDAV Workshop, &nbsp <font color="red"><strong>(Best Paper Award)</strong></font> </li>
                <li><b> Sep 2021, </b> <a href="https://pakheiyeung.github.io/ImplicitVol_wp/"> ImplicitVol: Sensorless 3D Ultrasound Reconstruction with Deep Implicit Representation.</a> Preprint  </li>
                <li><b> Sep 2021, </b> <a href="https://xiaoman-zhang.github.io/Layer-Decomposition/"> Self-supervised Tumor Segmentation through Layer Decomposition.</a> Preprint  </li>
                <li><b> July 2021, </b> <a href="https://charigyang.github.io/motiongroup/"> Self-supervised Video Object Segmentation by Motion Grouping.</a>
                Accepted by ICCV2021. &nbsp <font color="red"><strong>(Best Paper Award at CVPR Workshop)</strong></font> </li>
                <li><b> June 2021, </b> KeyNote at
                  <a href="https://eval.vision.rwth-aachen.de/rvsu-workshop21/"> CVPR2021 Robust Video Scene Understanding: Tracking and Video Segmentation.</a>
                <li><b> June 2021, </b> <a href="https://pakheiyeung.github.io/Sli2Vol_wp/"> Sli2Vol: Annotate a 3D Volume from a Single Slice with Self-Supervised Learning.</a>
                Accepted by MICCAI2021.</li>
                <li><b> April 2021, </b> <a href="https://nerfmm.active.vision"> NeRF--: Neural Radiance Fields Without Known Camera Parameters.</a> Paper & Code </li>
                <li><b> April 2021, </b> <a href="https://www.robots.ox.ac.uk/~vgg/research/lvs/"> Localizing Visual Sounds the Hard Way.</a> Paper & Code, to appear at CVPR2021 </li>
                <li><b> March 2021, </b> <a href="https://arxiv.org/abs/2103.14653"> Quantum Self-supervised Learning.</a> Preprint  </li>
              </ul>



            </td>
          </tr>
          </table>
                  </td>
              </tr>
            </table>
          </body>
          
          </html>
