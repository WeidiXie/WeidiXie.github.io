<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <!-- Please delete this script if you use this HTML. -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-7580334-1');
  </script>
  <meta name="viewport" content="width=500">
  <link href="stylesheet.css" rel="stylesheet" type="text/css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Weidi Xie</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="1200" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="middle">
              <p align="center">
                <name>Weidi Xie</name>
              </p>
              <p>I'm a research fellow at <a href="http://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a>,
                 where I work on computer vision, deep learning, biomedical image analysis.
              </p>
              <p>
                I completed my D.Phil in Engineering Science, University of Oxford, 2018,
              </p>
              <p>
                Advisors: <a href="https://scholar.google.co.uk/citations?user=b0tmmYMAAAAJ&hl=en">Professor Alison Noble</a> (BioMedIA)
                and <a href="https://scholar.google.co.uk/citations?user=UZ5wscMAAAAJ&hl=en">Professor Andrew Zisserman</a> (VGG),
              </p>
              <p>
                Thesis defence committees: <a href="https://scholar.google.co.uk/citations?user=bRT7t28AAAAJ&hl=en">Professor Andrea Vedaldi</a> (Oxford)
                and <a href="https://scholar.google.com/citations?user=H0O0WnQAAAAJ&hl=en">Professor Daniel Rueckert</a> (Imperial College London).
              </p>

              <p>
                I was a recipient of the <a href="https://www.admin.ox.ac.uk/personnel/reward/rewardandrecognitionscheme/awardsexcell/">Excellence Award</a> in 2018,
                from Department of Engineering Science, University of Oxford. <br>
                I was a recipient of <a href="http://www.ox.ac.uk/news/2018-11-15-deepmind-scholarships-encourage-wider-participation-computer-science"> Oxford-Google DeepMind Graduate Scholarships</a>
                on Machine Learning and Biomedical Image Analysis. <br>
                I was a recipient of Magdalen Award from <a href="https://chinaoxford.org">China Oxford Scholarship Fund (COSF)</a>
              </p>
              <p align=left>
                <a href="mailto:weidi@robots.ox.ac.uk">Email</a> &nbsp/&nbsp
                <a href="data/Weidi-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/Weidi-bio.txt">Biography</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=Vtrqj4gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/WeidiXie"> Twitter </a> &nbsp/&nbsp
                <a href="https://space.bilibili.com/626918756"> Bilibili </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/weidi-xie-81a59976/"> LinkedIn </a>
              </p>
            </td>
            <td width="35%">
              <img src="images/weidi_photo.png" width="300" height="300">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, biomedical image analysis.
              </p>
        </table>


          <heading>2020</heading>
            <p> </p>
            C20. &ensp;
              <a href="">
                <papertitle>Self-supervised Co-training for Video Representation Learning.</papertitle>
              </a>
              <br>
              Tengda Han,
              <strong>Weidi Xie</strong>, Andrew Zisserman <br>
              To appear in: <em>Thirty-fourth Conference on Neural Information Processing Systems (NeurIPS) </em>, 2020. <br>
              <a href="">Arxiv</a> /
              <a href="">Project Page</a> /
              <a href="">Code & Model</a>
              <p> </p>


          <p> </p>
            C19. &ensp;
              <a href="">
                <papertitle>Betrayed by Motion: Camouflaged Object Discovery via Motion Segmentation.</papertitle>
              </a>
              <br>
              Hala Lamdouar, Charig Yang, <strong>Weidi Xie</strong>, Andrew Zisserman<br>
              To appear in: <em>Asian Conference on Computer Vision (ACCV)</em>, 2020. <br>
              <a href="">Arxiv</a> /
              <a href="">Project Page</a>
              <p> </p>


            <p> </p>
            C18. &ensp;
              <a href="https://arxiv.org/abs/2009.07833">
                <papertitle>Layered Neural Rendering for Retiming People in Video.</papertitle>
              </a>
              <br>
              Erika Lu, Forrester Cole, Tali Dekel, <strong>Weidi Xie</strong>, Andrew Zisserman, David Salesin, William T. Freeman, Michael Rubinstein<br>
              To appear in: <em>ACM Transactions on Graphics (TOG). Proc. SIGGRAPH Asia </em>, 2020<br>

              <a href="https://arxiv.org/abs/2009.07833">Arxiv</a> /
              <a href="https://retiming.github.io">Project Page</a>
              <p> </p>

            <p> </p>
            C17. &ensp;
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Xie20/xie20.pdf">
                <papertitle>Inducing Predictive Uncertainty Estimation for Face Recognition.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>, Jeffrey Byrne, Andrew Zisserman<br>
              In: <em>British Machine Vision Conference (BMVC) </em>, 2020<br>
          <a href="https://arxiv.org/abs/2009.00603">Arxiv</a> /
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Xie20/xie20.pdf">PDF</a>
              <p> </p>

          <p> </p>
            C16. &ensp;
              <a href="https://arxiv.org/abs/2007.12163">
                <papertitle>Smooth-AP: Smoothing the Path Towards Large-Scale Image Retrieval.</papertitle>
              </a>
              <br>
              Andrew Brown, <strong>Weidi Xie</strong>, Vicky Kalogeiton, Andrew Zisserman<br>
              In: <em>European Conference on Computer Vision (ECCV) </em>, 2020<br>
               <a href="https://arxiv.org/abs/2007.12163">Arxiv</a> /
               <a href="https://www.robots.ox.ac.uk/~vgg/research/smooth-ap/">Project Page</a> /
              <a href="https://github.com/Andrew-Brown1/Smooth_AP">Code & Model</a>
              <p> </p>

          <p> </p>
            C15. &ensp;
              <a href="https://arxiv.org/abs/2008.01065">
                <papertitle>Memory-augmented Dense Predictive Coding for Video Representation Learning.</papertitle>
              </a>
              <br>
              Tengda Han,
              <strong>Weidi Xie</strong>, Andrew Zisserman <br>
              In: <em>European Conference on Computer Vision (ECCV) </em>, 2020
              &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font> <br>
              <a href="https://arxiv.org/abs/2008.01065">Arxiv</a> /
              <a href="http://www.robots.ox.ac.uk/~vgg/research/DPC/">Project Page</a> /
              <a href="https://tengdahan.github.io">Code & Model</a>
              <p> </p>

          <p> </p>
            C14. &ensp;
              <a href="https://arxiv.org/abs/2002.07793">
                <papertitle>MAST: A Memory-Augmented Self-Supervised Tracker.</papertitle>
              </a>
              <br>
              Zihang Lai,
              Erika Lu,
              <strong>Weidi Xie</strong> <br>
              In: <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020<br>
              <a href="https://arxiv.org/abs/2002.07793">Arxiv</a> /
              <a href="https://zlai0.github.io/MAST/">Project Page</a> /
              <a href="https://github.com/zlai0/MAST">Code & Model</a> /
              <p> </p>

            C13. &ensp;
              <a href="https://arxiv.org/abs/2004.14368">
                <papertitle>VGG-Sound: A Large-Scale Audio-Visual Dataset.</papertitle>
              </a>
              <br>
              Honglie Chen,
              <strong>Weidi Xie</strong>,
              Andrea Vedaldi,
              Andrew Zisserman <br>
              In: <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2020<br>
              <a href="https://arxiv.org/abs/2004.14368">Arxiv</a> /
              <a href="http://www.robots.ox.ac.uk/~vgg/data/vggsound/">Project Page</a> /
              <a href="https://github.com/hche11/VGGSound">Code & Model</a> /
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Chen20/chen20.pdf">PDF</a>
              <p> </p>

            J6. &ensp;
              <a href="https://ieeexplore.ieee.org/document/8999615">
                <papertitle>Low-Memory CNNs Enabling Real-Time Ultrasound Segmentation Towards Mobile Deployment.</papertitle>
              </a>
              <br>
              Sagar Vaze, <strong>Weidi Xie</strong>, Ana Namburete. <br>
              In: <em>IEEE Journal of Biomedical and Health Informatics</em>, 2020. (Impact Factor: ~4.2)<br>
              <a href="https://sgvaze.github.io/pages/lightweight_unets.html">Project Page</a>  /
              <a href="https://github.com/sgvaze/lightweight_unet">Code</a>
              <p> </p>


            J5. &ensp;
              <a href="https://www.sciencedirect.com/science/article/pii/S0885230819302712">
                <papertitle>VoxCeleb: Large-scale Speaker Verification in the Wild.</papertitle>
              </a>
              <br>
              Arsha Nagrani*, Joon Son Chung*, <strong>Weidi Xie*</strong>,
              Andrew Zisserman.  (* indicates equal contribution)<br>
              In: <em>Computer Speech & Language</em>, 2020. (Impact Factor: ~1.8)<br>
              <p> </p>


          <heading>2019</heading>
          <p> </p>

            T1. &ensp;
              <a href="https://arxiv.org/pdf/1912.02522.pdf">
                <papertitle>VoxSRC 2019: The first VoxCeleb Speaker Recognition Challenge.</papertitle>
              </a>
              <br>
              Joon Son Chung, Arsha Nagrani,
              Ernesto Coto,
              <strong>Weidi Xie</strong>,
              Mitchell McLaren, Douglas A Reynolds,
              Andrew Zisserman.<br>
              Tech Report<br>
              <p> </p>

            C12. &ensp;
            <a href="https://arxiv.org/abs/1909.04656">
                <papertitle>Video Representation Learning by Dense Predictive Coding.</papertitle>
              </a>
              <br> Tengda Han,
              <strong>Weidi Xie</strong>,
              Andrew Zisserman<br>
              In: <em>1st International Workshop on Large-scale Holistic Video Understanding, ICCV</em>, 2019.
              &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
             <a href="http://www.robots.ox.ac.uk/~vgg/research/DPC/">Project Page</a> /
             <a href="https://github.com/TengdaHan/DPC">Code</a> /
             <a href="https://arxiv.org/abs/1909.04656">Arxiv</a> /
              <a href="data/HanICCVW2019.bib">Bibtex</a>
              <p> </p>

            C11. &ensp;
            <a href="https://arxiv.org/abs/1905.00875">
                <papertitle>Self-supervised Learning for Video Correspondence Flow.</papertitle>
              </a>
              <br> Zihang Lai,
              <strong>Weidi Xie</strong> <br>
              In: <em>British Machine Vision Conference (BMVC)</em>, 2019.
              &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
             <a href="https://zlai0.github.io/CorrFlow/">Project Page</a> /
             <a href="https://arxiv.org/abs/1905.00875">Arxiv</a> /
              <a href="data/LaiBMVC2019.bib">Bibtex</a>
              <p> </p>

            C10. &ensp;
            <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/Chen19/chen19.pdf">
                <papertitle>AutoCorrect: Deep Inductive Alignment of Noisy Geometric Annotations.</papertitle>
              </a>
              <br> Honglie Chen,
              <strong>Weidi Xie</strong>,
              <a href="http://www.robots.ox.ac.uk/~vedaldi/"> Andrea Vedaldi</a>,
              Andrew Zisserman. <br>
              In: <em>British Machine Vision Conference (BMVC)</em>, 2019.
              &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font> <br>
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/Chen19/chen19.pdf">PDF</a> /
              <a href="data/ChenBMVC2019.bib">Bibtex</a>
              <p> </p>


            C9. &ensp;
            <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/xu19/xu19.pdf">
                <papertitle>Geometry-Aware Corner Network for Video Object Detection from Static Cameras.</papertitle>
              </a>
              <br> Dan Xu,
              <strong>Weidi Xie</strong>,
              Andrew Zisserman. <br>
              In: <em>British Machine Vision Conference (BMVC)</em>, 2019.
              &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/xu19/xu19.pdf">PDF</a> /
              <a href="data/XuBMVC2019.bib">Bibtex</a>
              <p> </p>

              C8. &ensp;
              <a href="https://arxiv.org/abs/1902.10107">
                <papertitle>Utterance-level Aggregation for Speaker Recognition in the Wild.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>,
              Arsha Nagrani, Joon Son Chung, Andrew Zisserman. <br>
              In: <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2019.
              &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
              <a href="http://www.robots.ox.ac.uk/~vgg/research/speakerID/">Project Page</a> /
              <a href="https://github.com/WeidiXie/VGG-Speaker-Recognition">Code & Model</a> /
              <a href="data/XieICASSP2019.bib">Bibtex</a>
              <p> </p>

          <heading>2018</heading>
          <p> </p>

              C7. &ensp;
              <a href="https://www.robots.ox.ac.uk/~vgg/publications/2018/Xie18a/xie18a.pdf">
                <papertitle>Comparator Networks.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>, Li Shen, Andrew Zisserman
              <br>
              In: <em>European Conference on Computer Vision (ECCV)</em>, 2018.
              <br>
              <a href="https://arxiv.org/abs/1807.11440">Arxiv</a> /
              <a href="data/XieECCV2018.bib">Bibtex</a>
              <p> </p>

              C6. &ensp;
              <a href="https://www.robots.ox.ac.uk/~vgg/publications/2018/Xie18b/xie18b.pdf">
                <papertitle>Multicolumn Networks on Face Recognition.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>, Andrew Zisserman
              <br>
              In: <em>British Machine Vision Conference (BMVC)</em>, 2018.
              <br>
              <a href="https://arxiv.org/abs/1807.09192">Arxiv</a> /
              <a href="https://github.com/WeidiXie/multicoumn_network">Code & Model</a> /
              <a href="data/XieBMVC2018.bib">Bibtex</a>
              <p> </p>

              C5. &ensp;
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2018/Lu18/lu18.pdf">
                <papertitle>Class-Agnostic Counting.</papertitle>
              </a>
              <br>
              Erika Lu, <strong>Weidi Xie</strong>, Andrew Zisserman
              <br>
              In: <em>Asian Conference on Computer Vision (ACCV)</em>, 2018.
              <br>
              <a href="http://www.robots.ox.ac.uk/~vgg/research/class-agnostic-counting/">Project Page</a> /
              <a href="https://arxiv.org/abs/1811.00472">Arxiv</a> /
              <a href="data/XieBMVC2018.bib">Bibtex</a>
              <p> </p>

              C4. &ensp;
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2018/Cao18/cao18.pdf">
                <papertitle>VGGFace2: A Dataset for Recognising Faces Across Pose and Age.</papertitle>
              </a>
              <br>
              Qiong Cao, Li Shen, <strong>Weidi Xie</strong>, Omkar M. Parkhi and Andrew Zisserman
              <br>
              In: <em>IEEE International Conference on Automatic Face and Gesture Recognition (F&G)</em>, 2018.
              &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/">Project Page</a> /
              <a href="https://arxiv.org/abs/1710.08092">Arxiv</a> /
              <a href="data/CaoFG2018.bib">Bibtex</a>
              <p> </p>

              J4. &ensp;
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518302998">
                <papertitle>Omega-Net: Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie*, Davis M. Vigneault*</strong>, Carolyn Y. Ho, David A. Bluemke and J. Alison Noble (* indicates equal contribution, joint first author)
              <br>
              In: <em>Medical Image Analysis, Volume 48, Pages 95, August 2018. (Impact Factor: ~11)</em>
              <br>
              <a href="https://arxiv.org/abs/1711.01094">Arxiv</a>
              <p> </p>


              J3. &ensp;
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518301920">
                <papertitle>VP-Nets: Efficient Automatic Localization of Key Brain Structures in 3D Fetal Neurosonography.</papertitle>
              </a>
              <br>
              Ruobing Huang, <strong>Weidi Xie</strong> and J. Alison Noble
              <br>
              In: <em>Medical Image Analysis, Volume 47, Pages 127, July 2018. (Impact Factor: ~11)</em>
              <br>
              <p> </p>


              J2. &ensp;
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518300306">
                <papertitle>Fully-Automated Alignment of 3D Fetal Brain Ultrasound to a Canonical Reference Space Using Multi-task Learning.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie*, Ana I.L. Namburete*</strong>,   Mohammad Yaqub,
              Andrew Zisserman and J. Alison Noble (* indicates equal contribution, joint first author)
              <br>
              In: <em>Medical Image Analysis, Volume 46, Pages 1, May 2018. (Impact Factor: ~11)</em>
              <br>
              <p> </p>


          <heading>2017</heading>
          <p> </p>

          C3. &ensp;
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-59448-4_18">
                <papertitle>Feature Tracking Cardiac Magnetic Resonance via Deep Learning and Spline Optimization.</papertitle>
              </a>
              <br>
              Davis M. Vigneaulta, <strong>Weidi Xie</strong>, David A. Bluemke and J. Alison Noble
              <br>
              In: <em>Functional Imaging and Modelling of the Heart (FIMH)</em>, 2017.
              &nbsp <font color="red"><strong>(Best Poster Award)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1704.03660">Arxiv</a>
              <p> </p>

          C2. &ensp;
              <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-67561-9_8">
                <papertitle>Robust Regression of Brain Maturation from 3D Fetal Neurosonography using CRNs.</papertitle>
              </a>
              <br>
              Ana I.L. Namburete, <strong>Weidi Xie</strong> and J. Alison Noble
              <br>
              In: <em>MICCAI Workshop on Fetal and InFant Image analysis (FIFI)</em>, 2017.
              &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
              <br>
              <a href="https://www.dropbox.com/s/ypyita3gabr2cs4/3d_brain_age.pdf?dl=0">Paper</a>
              <p> </p>

          <heading>2016</heading>
          <p> </p>

          C1 & J1. &ensp;
              <a href="https://www.tandfonline.com/doi/full/10.1080/21681163.2016.1149104">
                <papertitle>Microscopy Cell Counting and Detection with Fully Convolutional Regression Networks.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>, J. Alison Noble and Andrew Zisserman
              <br>
              In: <em>MICCAI 1st Deep Learning Workshop</em>, 2015.
              <br>
              In: <em>Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization</em>, 2016.
              &nbsp <font color="red"><strong>(Biannual Best Journal Article)</strong></font>
              <br>
              <a href="http://www.robots.ox.ac.uk/~vgg/publications/2016/Xie16/xie16.pdf">Paper</a> /
              <a href="https://github.com/WeidiXie/cell_counting_v2">Code</a> /
              <a href="https://think.taylorandfrancis.com/journal-prize-computer-methods-in-biomechanics-and-biomedical-engineering-imaging-visualization-best-paper-award/">Award</a>
              <p> </p>


        <heading>Dphil Thesis</heading>
        <p> </p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="30">
              <a href="https://ora.ox.ac.uk/objects/uuid:5fcfb784-7b61-49cd-9561-64b5ffa5807a">
                <papertitle>Deep Neural Networks in Computer Vision and Biomedical Image Analysis.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>
              <br>
              Dphil Thesis, Unversity of Oxford, 2018. <br>
        </table>
        <p> </p>


        <heading>Unpublished Papers</heading>
        <p> </p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="30">
              <a href="https://openreview.net/forum?id=rJJRDvcex">
                <papertitle>Layer Recurrent Neural Networks.</papertitle>
              </a>
              <br>
              <strong>Weidi Xie</strong>, J. Alison Noble and Andrew Zisserman
              <br>
              Technical Report, 2017.
              <a href="https://openreview.net/pdf?id=rJJRDvcex">URL</a>
        </table>
        <p> </p>

            <!-- Please delete this script if you use this HTML. -->
        <!-- <heading>Service</heading>
        <p> </p>

        <table width="100%" align="center" border="0" cellpadding="20">
              Conference Review: CVPR, ICCV, ECCV, MICCAI, BMVC <br>
              <p style="text-indent: 10px"></p>
              Journal Review:
                 <p style="text-indent: 10px">BMC Bioinformatics</p>
                 <p style="text-indent: 10px">ACM Computing Surveys</p>
                 <p style="text-indent: 10px">IEEE Transactions on Medical Imaging</p>
                 <p style="text-indent: 10px">International Journal of Computer Vision</p>
                 <p style="text-indent: 10px">IEEE Journal of Biomedical and Health Informatics</p>
                 <p style="text-indent: 10px">Transactions on Pattern Analysis and Machine Intelligence</p>
                 <p style="text-indent: 10px">IEEE Transactions on Biometrics, Behavior, and Identity Science</p>
        </table>
        -->

      </td>
    </tr>
  </table>
</body>

</html>
